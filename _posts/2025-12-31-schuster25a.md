---
abstract: Sparse autoencoders (SAEs) have lately been used to uncover interpretable
  latent features in large language models. By projecting dense embeddings into a
  much higher-dimensional and sparse space, learned features become disentangled and
  easier to interpret. This work explores the potential of SAEs for decomposing embeddings
  in complex and high-dimensional biological data. Using simulated data, it outlines
  the efficacy, hyperparameter landscape, and limitations of SAEs when it comes to
  extracting ground truth generative variables from latent space. The application
  to embeddings from pretrained single-cell models shows that SAEs can find and steer
  key biological processes and even uncover subtle biological signals that might otherwise
  be missed. This work further introduces scFeatureLens, an automated interpretability
  approach for linking SAE features and biological concepts from gene sets to enable
  large-scale analysis and hypothesis generation in single-cell gene expression models.
title: Can sparse autoencoders make sense of gene expression latent variable models?
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: schuster25a
month: 0
tex_title: Can sparse autoencoders make sense of gene expression latent variable models?
firstpage: 81
lastpage: 94
page: 81-94
order: 81
cycles: false
bibtex_author: Schuster, Viktoria
author:
- given: Viktoria
  family: Schuster
date: 2025-12-31
address:
container-title: Proceedings of the 20th Machine Learning in Computational Biology
  meeting
volume: '311'
genre: inproceedings
issued:
  date-parts:
  - 2025
  - 12
  - 31
pdf: https://raw.githubusercontent.com/mlresearch/v311/main/assets/schuster25a/schuster25a.pdf
extras:
- label: Supplementary PDF
  link: https://raw.githubusercontent.com/mlresearch/v311/main/assets/assets/schuster25a/schuster25a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
